---
title: 知识抽取与知识挖掘
author: Jarrycow
img: /medias/featureimages/xxx.png
cover: false
top: false
mathjax: true
categories:
  - 知识图谱
tags:
  - 知识图谱
  - 人工智能
keywords: 知识抽取与知识挖掘
abbrlink: KnowledgeExtraction
date: 2023-02-04 09:41:53
---

知识抽取是构建大规模知识图谱重要环节，而知识挖掘是已有知识图谱基础上发现隐藏知识

<!--more-->

# 知识抽取任务

知识抽取目的是从不同来源不同结构数据中进行知识提取并存入知识图谱。知识抽取数据源可是结构化数据<sub>链接数据、数据库</sub>、半结构化数据<sub>网页中表格、列表</sub>、非结构化数据<sub>纯文本数据</sub>。

知识抽取最早出现于 NLP 指自动化从文本中发现和抽取相关信息，并将多个文本碎片信息合并，将非结构化数据转换为结构化数据。

**子任务：**

- **命名实体检测：**从文本检测出命名实体，并分类到预定义类别中
- **关系抽取：**从文本中识别实体之间联系
- **事件抽取：**识别文本中关于事件信息并以结构化形式呈现

# 面向非结构化数据的知识抽取

大多数数据以非结构化数据<sub>自由文本</sub>形式存在。

## 实体抽取

实体抽取即从文本中抽取实体信息元素，是知识抽取基本任务。首先，需要从文本中识别和定位，再将识别的实体分类到预定义的类别中。

### 基于规则的方法

早期命名实体识别采用人工编写规则，首先构建大量实体抽取规则，由该领域专家手工构建；然后将规则与本文字符串匹配识别实体。这种抽取方式准确率和召回率很高，但随着数据集增大，构建周期变长，移植性较差。

### 基于统计模型方法

利用完全标注或部分标注语料进行训练，主要采用模型包括隐马尔可夫、条件马尔可夫、最大熵、条件随机场。将命名实体识别作为序列标注问题处理，当前标签预测不仅与当前输入特征相关，还与之前预测标签相关，即预测标签序列强相互依赖。

基于统计模型构建命名实体识别主要涉及训练语料标注、特征定义、模型训练：

- **训练语料标注：**为构建统计模型训练语料，一般采用 IOB 或 IO 标注体系对文本人工标注。在 IOB 标注体系中，文本中每个词被标记为起始词 B、实体名称后缀词 I、实体名称外部词 D。

- **特征定义：**训练模型之前，统计模型需要计算每个词一组特征作为模型输入。特征具体包括单词级别特征<sub>首字母大写、句点收尾、包含数字、词性等</sub>、词典特征<sub>词典定义</sub>和文档特征<sub>基于整个语料文档计算</sub>

- **模型训练：**隐马尔可夫模型和条件随机场是常用标注问题的统计学习模型，也被广泛用于实体抽取。HMM 是一种有向图概率模型，模型中包含隐藏状态序列和可观测序列，每个状态代表一个可观察事件。HMM 模型基本假设：

  - 在任意 $t$ 时刻状态只依赖其前一刻状态，与其他观测及状态无关：
    $$
    P\left( x_t|x_{t-1},x_{t-2},\cdots ,x_1,y_{t-1},y_{t-2},\cdots ,y_1 \right) =P\left( x_t|x_{t-1} \right) 
    $$
    
  - 任意时刻观测只依赖于该时刻马尔科夫链状态，与其他观测状态无关：
    $$
    P\left( y_t|x_t,x_{t-1},x_{t-2},\cdots ,x_1,y_{t-1},y_{t-2},\cdots ,y_1 \right) =P\left( y_t|x_t \right)
    $$

![HMM 模型结构](https://raw.githubusercontent.com/Jarrycow/picHost/main/KnowledgeGraphs/%E6%89%AB%E6%8F%8F%E5%85%A8%E8%83%BD%E7%8E%8B%202023-02-04%2011.10.jpg)

### 基于深度学习的方法

以文本中词向量作为输入，通过神经网络实现端到端命名实体特征，得到每个词新向量表示，最后通过 CRF 输出每个词标注结果

#### LSTM-CRF 模型

该模型自底向上为 Embedding 层、双向 LSTM 层、CRF 层。Embedding 层是句子中词向量表示，作为双向 LSTM 输入；双向 LSTM 层分别计算每个词考虑左侧和右侧词对应向量；CRF 层对句子中命名实体进行序列标注。

![LSTM-CRF 模型](https://raw.githubusercontent.com/Jarrycow/picHost/main/KnowledgeGraphs/%E6%89%AB%E6%8F%8F%E5%85%A8%E8%83%BD%E7%8E%8B%202023-02-04%2015.00.jpg)

#### LSTM-CNNs-CRF 模型

在 LSTM-CRF 模型中的 Embedding 层中加入每个词字符级向量表示<sub>使用 CNN</sub>

![LSTM-CNNs-CRF 模型](https://raw.githubusercontent.com/Jarrycow/picHost/main/KnowledgeGraphs/%E6%89%AB%E6%8F%8F%E5%85%A8%E8%83%BD%E7%8E%8B%202023-02-04%2015.00_2.jpg)

#### 基于注意力机制的神经网络模型

注意力机制最早用于机器翻译，注意力机制可扩展基本编码器-解码器模型结构，让模型能获取输入序列与下一个目标词相关信息。

![基于注意力机制词向量和字符级向量组合方法](https://raw.githubusercontent.com/Jarrycow/picHost/main/KnowledgeGraphs/%E6%89%AB%E6%8F%8F%E5%85%A8%E8%83%BD%E7%8E%8B%202023-02-04%2015.19.jpg)

## 关系抽取

关系抽取即从文本中抽取多个实体之间语义关系。一般在识别出文本实体后，抽取实体之间存在关系。

### 基于模板关系抽取方法

早期实体关系抽取大多基于模板匹配实现，由专家手动编写。

例子：从文本中抽取“夫妻”关系

> 模板1：[X]与妻子[Y]
>
> 模板2：[X]老婆[Y]

**优点：**关系简单，可较快在小规模数据集实现关系抽取系统

**缺点：**数据规模较大，手工构建模板需耗费大量专家；移植性较差

### 基于监督学习关系抽取方法

在大量标注数据基础上，训练有监督学习模型进行关系抽取。关系抽取特征定义对抽取结果具有较大影响。传统基于监督学习关系抽取依赖特征工程方法；近年来深度学习方法则不需要人工构建各种特征，只需要输入句子中词及位置向量表示

目前基于深度学习关系抽取方法包括流水线方法和联合抽取方法。流水线方法将识别物体和关系抽取作为分离过程进行处理，两者不会互相影响；关系抽取在实体抽取结果基础进行，因此关系抽取结果依赖于实体抽取。联合抽取将实体抽取和关系抽取结合在统一模型中共同优化。

#### 基于深度学习流水线关系抽取方法

- **CR-CNN 模型**
- **Attention CNNs 模型**
- **Attention BLSTM 模型**

#### 基于深度学习联合关系抽取方法

流水关系抽取方法中，实体抽取和关系抽取两个过程分离。联合关系抽取方法则是将实体抽取和关系抽取结合。

该模型由三个表示层组成：词嵌入、基于单词序列的 LSTM-RNN 层、基于依赖性子树的 LSTM-RNN 层。

![实体抽取和关系抽取联合模型](https://raw.githubusercontent.com/Jarrycow/picHost/main/KnowledgeGraphs/%E6%89%AB%E6%8F%8F%E5%85%A8%E8%83%BD%E7%8E%8B%202023-02-04%2017.20.jpg)

#### 基于弱监督学习关系抽取法

当训练语料不足时，弱监督学习方法可以只利用少量标注数据进行模型学习

##### 远程监督方法

将知识图谱非结构化文本对齐方式自动构建大量训练数据，减少模型对人工标注数据依赖。

**基本假设：**两个实体在知识图谱中存在某种关系，则包含两种实体的句子均表达了这种关系

**步骤：**

1. 从知识图谱抽取存在目标关系实体对
2. 从非结构化中抽取含有实体对的句子作为训练样例
3. 训练监督学习模型进行关系抽取

**优点：**利用丰富知识图谱信息获取数据，有效减少人工标注工作量

**缺点：**引入大量噪声到训练数据中，从而引发语义漂移

**改进：**多示例学习、深度学习模型用以克服训练数据中的噪声

##### Bootstrapping 方法

利用少量实例作为初始种子集合，在种子集合上学习获得关系抽取模板，再利用模板抽取更多实例，加入种子集合中不断迭代。

**优点：**构建成本低，适合大规模关系抽取任务，具备发现新关系的能力

**缺点：**对初始种子较为敏感，存在语义漂移，结果准确率低

## 事件抽取

从自然语言中抽取事件属性<sub>时间、地点、人物</sub>，并结构化表示。

### 事件抽取的流水线方法

将事件抽取人物分解为一系列基于分类子任务<sub>事件识别、元素抽取、属性分类、可报告性判别</sub>，每个子任务由一个机器学习分类器负责实施。

一个事件抽取流水线需要分类器包括：

- 事件触发词分类器：判断词汇是否为事件触发词，基于触发词信息对事件类别进行分类
- 元素分类器：判断词组是否为事件元素
- 元素角色分类器：判定事件元素的角色类别
- 属性分类器：判定事件属性
- 可报告分类器：判断是否存在值得报告的事件实例

### 事件联合抽取方法

事件抽取流水线方法在每个子任务阶段都可能存在误差，这种误差从前面环节逐步转播到后面环节从而导致误差不断积累，使得事件抽取性能急剧骤减。在事件联合抽取方法中，事件所有信息会通过一个模型同时抽取出来，即采用联合推断或联合建模。

首先建立事件抽取子任务模型，然后将各个模型目标函数进行组合，形成联合推断的目标函数；通过对目标函数优化获得事件抽取各个子任务结果。

# 面向结构化数据的知识抽取

垂直领域知识往往来源于支撑企业业务系统关系数据库，因此从数据库结构化数据中抽取知识也很重要。

## 直接映射

定义关系数据库到 RDF 图简单转换，为定义和比较更复杂转换提供基础。可以实现 RDF 图或定义虚拟图，通过 SPARQL 查询或通过 RDF 图用 API 访问。直接映射基本规则包括：

- 数据库表映射为 RDF 类
- 数据库中表的列映射为 RDF 类
- 数据库表中每一行映射为一个资源或实体，创建 IRI
- 数据库表中每个单元格值映射为一个文字值；如果单元格值对应一个外键，则将其替换为外键值指向资源或实体 IRI

## R2RML

表示从关系数据库到 RDF 数据集自定义映射语言，提供 RDF 数据模型查看现有关系型数据能力，且可基于用户自定义结构和目标词汇表示原有关系型数据。在数据库直接映射中，生成 RDF 图的结构直接反映数据库结构，目标 RDF 词汇直接反映数据库模式元素名称，结构和目标词汇都不能改变。但通过使用 R2RML 用户可以在关系数据上灵活定制视图。

R2RML 映射通过逻辑表从数据库中检索数据，每个逻辑表可以通过三元组映射至 RDF 数据，逻辑表突破关系数据库表物理结构限制，为不改变数据库原有结构而灵活生成 RDF 奠定基础。

# 面向半结构化数据的知识抽取

半结构化数据即特殊数据形式，该形式数据不符合关系数据库或其他形式数据表结构，但又包含标签或其他标记分离语义元素并保持记录和数据字段的层次结构<sub>百科类数据、网页数据</sub>

## 面向百科类数据的知识抽取

以维基百科为例，其词条中标题、摘要、链接、分类、信息框均为半结构化数据。

DBpeipa 是大规模多语言百科知识图谱，是维基百科结构化版本。DBpeipa 采用固定模式对维基百科实体信息进行抽取，将其以关联数据形式在 Web 上发布分享。框架组成：

- 页面集合：包含本地以及远程维基百科文章数据
- 目标数据：存储或序列化提取的 RDF 三元组
- 将特定类型维基标记转换为三元组提取器
- 支持提取器解析器：确定数据类型，在不同单元间转换值并将标签分解成列表
- 知识提取管理器：将百科文章传递给提取器并输出传递到目标数据过程

![DBpedia 知识抽取总体框架](https://raw.githubusercontent.com/Jarrycow/picHost/main/KnowledgeGraphs/%E6%89%AB%E6%8F%8F%E5%85%A8%E8%83%BD%E7%8E%8B%202023-02-04%2022.30.jpg)

**DBpedia 知识提取器：**

- **标签：**抽取维基百科标题
- **摘要：**词条第一段文字<sub>最长 500</sub>
- **跨语言链接：**词条指向其他语言版本的链接
- **图片：**指向图片链接
- **重定向：**抽取重定向链接，建立同义词关联
- **消歧：**抽取有歧义词条
- **外部链接：**正文指向外部链接
- **页面链接：**正文指向维基内部链接
- **主页：**抽取机构实体主页
- **分类：**抽取词条所属分类
- **地理坐标：**抽取词条内部地理位置经纬度
- **信息框：**从词条信息框中抽取实体结构化信息

## 面向 Web 网页的知识抽取

网页具有丰富数据，且具有 HTML 结构。

### 手工方法

通过人工查看网页代码，在人工分析基础上，手工编写适合当前网站抽取表达式<sub>CSS 选择器表达式</sub>。

### 包装器归纳方法

基于有监督学习方法从已标注的训练样例集合中学习信息抽取规则，然后对相同模板其他网页进行数据抽取：

1. 网页清洗：纠正清理不规范标签<sub>TIDY 工具</sub>
2. 网页标注：在网页标注要抽取数据，给网页某个位置打上特殊标签
3. 包装器空间生成：基于标注数据生成 XPath 集合空间，对生成集合进行归纳形成若干子集<sub>使子集中 XPath 能覆盖尽可能多已标注数据，使其具有一定泛化能力</sub>
4. 包装器评估：通过准确率和召回率评估

### 自动抽取方法

包装器归纳同样需要大量人工标注，因而不适用大量站点知识抽取。除此之外一旦网站改版，则全部工作木大。自动抽取方法中相似的网页通过聚类分成若干组，通过挖掘同组相似网页重复模式，生成适用网页包装器。

# 知识挖掘

知识挖掘是从已有实体和实体间关系挖掘新知识。

## 知识内容挖掘：实体链接

将文本实体指称指向其给定知识库中目标实体的过程。实体链接可以将文本数据转换为有实体标注的形式，建立文本与知识库的联系。

![实体链接基本流程](https://raw.githubusercontent.com/Jarrycow/picHost/main/KnowledgeGraphs/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B.jpg)

### 实体链接基本流程

1. **实体指称识别：**识别出文本中实体名称<sub>通过命名识别技术或词典匹配技术</sub>
2. **候选实体生成：**确定文本中实体指称可能指向实体集合。
   - 表层名字扩展：某些实体是全名一部分，因此可以从实体及相关文档中识别其他可能扩展变体
   - 基于搜索引擎方式：将实体提及和上下文文字提交至搜索引擎，根据结果返回候选实体
   - 构建查询实体引用表：建立实体提及与候选实体对应关系，可视作<键，值>映射，一个键对应一到多个值
3. **候选实体消歧：**为每一个实体指称确定其指向的实体
   - 基于图的方法：将实体指称、实体、关系通过图表现
   - 基于概率生成模型的方式：通过对模型推理求解实体消歧问题
   - 基于主题模型的方法：在同一个文本中出现的实体应该与文本表述主题相关
   - 基于深度学习方法：评价实体之间相关度

## 知识结构挖掘：规则挖掘

### 归纳逻辑程序设计 ILP

以一阶逻辑归纳为理论基础，并以一阶逻辑为表达语言符号规则学习算法。知识图谱中实体关系可视作二元谓词描述事实，因此可通过 ILP 方法从知识图谱中学习一阶逻辑规则。给定背景知识和目标谓词，ILP 系统可学习获得描述目标谓词的逻辑规则集合。

### 路径排序算法 PRA

将关系路径作为特征的知识图谱链接预测算法，因为其获取关系路径实际上对应一种霍恩子句，即 PRA 计算路径可转换为逻辑规则便于发现和理解知识图谱中隐藏的知识。

**基本思想：**为链接两个实体的一组关系路径来预测实体之间存在的特殊关系。

**步骤：**

1. 特征选择：不使用所有连接实体关系路径作为模型特征，仅保留对于预测目标关系潜在有用关系路径。为保证特征选择效率，PRA 使用基于随机游走特征选择方法：对于某个关键路径 $\pi$，准确度 $precision$ 和覆盖度 $coverage$：
   $$
   precision(\pi)=\dfrac1n\sum_iP\left(s_i\rightarrow G_i;\pi\right)
   $$

   $$
   coverage(\pi)=\sum_il\left(P\left(s_i\rightarrow G_i;\pi\right)>0\right)
   $$
   
   其中，$P\left(s_i\rightarrow G_i;\pi\right)$ 是以实体 $s_i$ 起点，沿着关系路径 $\pi$ 随机游走能够抵达目标实体的概率。只有当准确度和覆盖度均不低于阈值时才作为特征保留
   
2. 特征计算：选择有用关系路径作为特征后，PRA 为每个实体计算特征值。给定实体对 $(h, t)$ 和某一特征路径 $\pi$，PRA 将从实体 $s$ 为起点沿着关系路径 $\pi$ 进行随机游走抵达实体 $t$ 概率作为该实体在关系路径 $\pi$ 特征的值。通过计算实体在每个特征关系路径上可达概率，可得该实体对所有特征值的值

3. 关系分类：基于训练样例和特征，PRA 为每个目标关系训练一个分类模型。利用训练完模型，可以预测知识图谱中任意两个实体之间是否存在某特定关系。关系分类可以使用任何分类模型，PRA 使用逻辑回归取得良好效果
